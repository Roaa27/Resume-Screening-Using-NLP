{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Roaa27/Resume-Screening-Using-NLP/blob/main/res_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ1ydKsMNTyB"
      },
      "source": [
        "Step 1: Install and Import Libraries  \n",
        "In this step, I installed the required libraries (`sentence-transformers`, scikit-learn, and `pandas`) and imported the necessary modules for data processing, embeddings, and similarity calculation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5qaMN302oJr",
        "outputId": "03333c29-b185-4a67-a560-1e3f54a4952a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence-transformers scikit-learn pandas\n",
        "\n",
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "print(\"✅ Libraries installed and imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Sj9tI3YNVkK"
      },
      "source": [
        "Step 2: Upload the Datasets  \n",
        "Here, I uploaded two datasets:  \n",
        "- UpdatedResumeDataSet.csv → contains candidate resumes.  \n",
        "- job_descriptions_sample.csv → contains job descriptions (a smaller sampled version for faster processing).  \n",
        "After uploading, I loaded both datasets into Pandas DataFrames and displayed their first few rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ch3y-GQb3Aoa",
        "outputId": "06c48d25-2fd9-4725-ead0-0e10f0cfbf3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "⬆️ Upload UpdatedResumeDataSet.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-276cca02-5f3a-4ecc-bb96-8134c01fe9a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-276cca02-5f3a-4ecc-bb96-8134c01fe9a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving UpdatedResumeDataSet.csv to UpdatedResumeDataSet (3).csv\n",
            "⬆️ Upload job_descriptions_sample.csv\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9a44c75f-3aff-46f9-a996-379f2e944f56\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9a44c75f-3aff-46f9-a996-379f2e944f56\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving job_descriptions_sample.csv to job_descriptions_sample.csv\n",
            "\n",
            "✅ Data loaded successfully!\n",
            "       Category                                             Resume\n",
            "0  Data Science  Skills * Programming Languages: Python (pandas...\n",
            "1  Data Science  Education Details \\r\\nMay 2013 to May 2017 B.E...\n",
            "2  Data Science  Areas of Interest Deep Learning, Control Syste...\n",
            "3  Data Science  Skills â¢ R â¢ Python â¢ SAP HANA â¢ Table...\n",
            "4  Data Science  Education Details \\r\\n MCA   YMCAUST,  Faridab...\n",
            "         Job Id     Experience Qualifications Salary Range    location  \\\n",
            "0  1.089840e+15  5 to 15 Years         M.Tech    $59K-$99K     Douglas   \n",
            "1  3.984540e+14  2 to 12 Years            BCA   $56K-$116K    Ashgabat   \n",
            "2  4.816400e+14  0 to 12 Years            PhD   $61K-$104K       Macao   \n",
            "3  6.881930e+14  4 to 11 Years            PhD    $65K-$91K  Porto-Novo   \n",
            "4  1.170580e+14  1 to 12 Years            MBA    $64K-$87K    Santiago   \n",
            "\n",
            "            Country  latitude  longitude  Work Type  Company Size  ...  \\\n",
            "0       Isle of Man   54.2361    -4.5481     Intern         26801  ...   \n",
            "1      Turkmenistan   38.9697    59.5563     Intern        100340  ...   \n",
            "2  Macao SAR, China   22.1987   113.5439  Temporary         84525  ...   \n",
            "3             Benin    9.3077     2.3158  Full-Time        129896  ...   \n",
            "4             Chile  -35.6751   -71.5429     Intern         53944  ...   \n",
            "\n",
            "                 Contact                     Job Title  \\\n",
            "0   001-381-930-7517x737  Digital Marketing Specialist   \n",
            "1           461-509-4216                 Web Developer   \n",
            "2             9687619505            Operations Manager   \n",
            "3  +1-820-643-5431x47576              Network Engineer   \n",
            "4      343.975.4702x9340                 Event Manager   \n",
            "\n",
            "                        Role    Job Portal  \\\n",
            "0       Social Media Manager      Snagajob   \n",
            "1     Frontend Web Developer      Idealist   \n",
            "2    Quality Control Manager  Jobs2Careers   \n",
            "3  Wireless Network Engineer      FlexJobs   \n",
            "4         Conference Manager  Jobs2Careers   \n",
            "\n",
            "                                     Job Description  \\\n",
            "0  Social Media Managers oversee an organizations...   \n",
            "1  Frontend Web Developers design and implement u...   \n",
            "2  Quality Control Managers establish and enforce...   \n",
            "3  Wireless Network Engineers design, implement, ...   \n",
            "4  A Conference Manager coordinates and manages c...   \n",
            "\n",
            "                                            Benefits  \\\n",
            "0  {'Flexible Spending Accounts (FSAs), Relocatio...   \n",
            "1  {'Health Insurance, Retirement Plans, Paid Tim...   \n",
            "2  {'Legal Assistance, Bonuses and Incentive Prog...   \n",
            "3  {'Transportation Benefits, Professional Develo...   \n",
            "4  {'Flexible Spending Accounts (FSAs), Relocatio...   \n",
            "\n",
            "                                              skills  \\\n",
            "0  Social media platforms (e.g., Facebook, Twitte...   \n",
            "1  HTML, CSS, JavaScript Frontend frameworks (e.g...   \n",
            "2  Quality control processes and methodologies St...   \n",
            "3  Wireless network design and architecture Wi-Fi...   \n",
            "4  Event planning Conference logistics Budget man...   \n",
            "\n",
            "                                    Responsibilities  \\\n",
            "0  Manage and grow social media accounts, create ...   \n",
            "1  Design and code user interfaces for websites, ...   \n",
            "2  Establish and enforce quality control standard...   \n",
            "3  Design, configure, and optimize wireless netwo...   \n",
            "4  Specialize in conference and convention planni...   \n",
            "\n",
            "                            Company  \\\n",
            "0                 Icahn Enterprises   \n",
            "1      PNC Financial Services Group   \n",
            "2  United Services Automobile Assn.   \n",
            "3                              Hess   \n",
            "4                      Cairn Energy   \n",
            "\n",
            "                                     Company Profile  \n",
            "0  {\"Sector\":\"Diversified\",\"Industry\":\"Diversifie...  \n",
            "1  {\"Sector\":\"Financial Services\",\"Industry\":\"Com...  \n",
            "2  {\"Sector\":\"Insurance\",\"Industry\":\"Insurance: P...  \n",
            "3  {\"Sector\":\"Energy\",\"Industry\":\"Mining, Crude-O...  \n",
            "4  {\"Sector\":\"Energy\",\"Industry\":\"Energy - Oil & ...  \n",
            "\n",
            "[5 rows x 23 columns]\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import pandas as pd\n",
        "\n",
        "print(\"⬆️ Upload UpdatedResumeDataSet.csv\")\n",
        "uploaded = files.upload()\n",
        "resumes = pd.read_csv(\"UpdatedResumeDataSet.csv\")\n",
        "\n",
        "print(\"⬆️ Upload job_descriptions_sample.csv\")\n",
        "uploaded = files.upload()\n",
        "jobs = pd.read_csv(\"job_descriptions_sample.csv\")\n",
        "\n",
        "print(\"\\n✅ Data loaded successfully!\")\n",
        "print(resumes.head())\n",
        "print(jobs.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z14Fwu-DNYJB"
      },
      "source": [
        "Step 3: Inspect Dataset Columns  \n",
        "I printed the column names from both datasets to confirm which fields to use for embedding:  \n",
        "- From resumes → Resume  \n",
        "- From jobs → Job Description and Job Title  \n",
        "This helps avoid errors due to column name mismatches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkXSIOFM5w5C",
        "outputId": "c01086c1-4c6d-4487-e383-f1853724483f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['Category', 'Resume'], dtype='object')\n",
            "Index(['Job Id', 'Experience', 'Qualifications', 'Salary Range', 'location',\n",
            "       'Country', 'latitude', 'longitude', 'Work Type', 'Company Size',\n",
            "       'Job Posting Date', 'Preference', 'Contact Person', 'Contact',\n",
            "       'Job Title', 'Role', 'Job Portal', 'Job Description', 'Benefits',\n",
            "       'skills', 'Responsibilities', 'Company', 'Company Profile'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "print(resumes.columns)\n",
        "print(jobs.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j5FrFaVENaLC"
      },
      "source": [
        "Step 4: Load the Embedding Model  \n",
        "I loaded the pre-trained all-MiniLM-L6-v2 model from SentenceTransformers.  \n",
        "This model converts text into numerical embeddings that capture semantic meaning, which we will use to compare resumes and job descriptions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511,
          "referenced_widgets": [
            "4c1633a5dfc44c1d91ab4c6978b3724c",
            "551df31994554e19a2e71a877d51030f",
            "6c83311becfc4d4b8629af4fe2995f20",
            "eb47cce4c57f4c7c8e044cd383259181",
            "d8c49357601c4321b17d5a2e90332e3a",
            "3274757729834302acb4b7257f96de3d",
            "8c9e40c69d9b44da9e9c90c3ab661e19",
            "d7111adcd5624596a4ffa4253e85356c",
            "b389c424ba82435dba49ccf9ea433fba",
            "6878787aceca4cb2ba61548d17e48c9d",
            "2e42ff941f4241ee88d520f3b2e830d9",
            "10001a3a041b43a48b4f6fa91cf8fb34",
            "9d49bd9a71b64a84b77f0b35779ecd81",
            "1e13933df21143dda1572b5ed6d3cc0d",
            "88555f354674480dbcbc9af0549df201",
            "b2b27368983e4dfcbb48315eecf816e5",
            "e656541a28674d1898c008d5082a1c74",
            "8f5e94f684c048f181fb2206a9e88ba5",
            "b4b079dc7efc4722b7e13e39b4702601",
            "760848b592604ba687d24cf8c92259fb",
            "2fb9ceded4884d6ab786e1b0bec3365b",
            "4614bddc8e1b4ff9b42f88ba8f3f6131",
            "784dbe227b494b0d99e28dcc34c28b4a",
            "d2ffb21c122c49a8a94512c64f350aaa",
            "66d7c1d79b024d9198d56f458cb2300d",
            "1beff597d6fc49f0a2b6740bb1383099",
            "ae44c875b80843af9d40bd6a8b47e8aa",
            "aafa2de03ead4b36a615a3906bad1b80",
            "b5e9b8ab891347e9823eea23b510eaf1",
            "fb57e5dd511247b1b45193833a6d7256",
            "ea3e581f47ac4d5a829a33fdccd83e83",
            "83c5c1ea7c5e4ecdb363cbda8a4beefc",
            "afb23038c5444d71942e16272fd1109c",
            "0aac41b423db4e90bc31c9b3b47d6a09",
            "d349fbb31abf4caeb561b89adc13d2b4",
            "219ee49c670d495788434d742a946725",
            "518f1b37327e4875aad90331bb03fdf4",
            "b8b93a64975443f9bfcbe4e490781ffa",
            "ba4ee3bbe22e439984aa26a1834bcc1b",
            "ae986c7259ec4f78892272be1b9a330f",
            "ff09ad4013dd45b8b5558a434ab26eb3",
            "ca63acf0a3a84d2f8533edd7a40aab05",
            "e97d66a4203744b988892f5859dc9445",
            "bc24cd23ad98402bb14a9647900570ba",
            "a5d801d50f7e4fa3965199a2efa731f3",
            "28f779dd3d7c4b328e4082af7bac0b9e",
            "b38401d7f70c4dc2a5d3dab7d1d906ba",
            "c63efabbd2304d21bc207e6020f04c6f",
            "44037b8622e94b59b3ff28e922a442a0",
            "7193a1bd76ee4a24bd3bb5254ab28e85",
            "0ffed08f81114fae8299401a466a1aef",
            "8258a9b5f7d7408b8642cfafa123cf1b",
            "ceb571c88c1145c8a6d3c00b4fceaa38",
            "dbebb4932921461fa9395b1550b2dfe7",
            "142a20b418624ea79d2e3b33459b9c2d",
            "8d490f44c768453f85f2df139568b9ad",
            "8a38ce8045d54673ab0896daca8e71e7",
            "b12b9e380f4f471b8826de5d9335ffd8",
            "a41c4bb916394c59a4ca59429ab0fd0d",
            "63e26bc211ca4ff089322c26145e83f7",
            "4e01602889f34aa69a47e2890a6b4398",
            "52c57cf389344135868a20207d4cd7c3",
            "efcc122df5f347828a3fd46b383ec4cd",
            "b54534d2439e4e0d9f6b5238d8566d4e",
            "eb78cae8ff85417b85996d8f021ed1ba",
            "1968f410e5724b49a386612fbf5a71b1",
            "9eff638e26b34ea6bfd2a1d49be4a447",
            "37c328961cff400f94909acdb8322b01",
            "349cc0cde77b4a989dc598e43960bdea",
            "a8312f30f87b40d1bdbb10b604c956a9",
            "96d872fe3c1f49778767a59b87a9080f",
            "d960ab77983148b4b4802717490600c5",
            "7c592375ac66494eb2ff691e26e8e98e",
            "5cae20e5675647afa7fd1bb6da03bc4e",
            "030ff1ade5004fa59834ab4a6f27085a",
            "db66d2a043bd4a429ece412265c44503",
            "11c5238d33f3443e96f932b104c79cf0",
            "23d714f3ba5048d1bbdd2492e5b99da3",
            "0151615b05f543b7811fbc30178129c0",
            "422d6db2e63f4a35a7892b227d66b4d3",
            "7b8f52989a424ac28edee674ec1740d2",
            "c7b269e0ae5b4dfe872460a9c8c773ad",
            "024af3b2369648669d9ccf9eeff4529f",
            "deaf4e743cbb4cf09585ffe80cd6d73c",
            "120a2451333145f9a419ab1b32ec723a",
            "a79fe8f8b3704ac282cd09604752af73",
            "e7c026bef8c34b2f8b219806fc63e223",
            "83c9f80e04474471b534db6aeffa51eb",
            "69ed913670544724990d23967ab8e94e",
            "fdad0fc76e604910a9bb9cfd0235f990",
            "b499e6925f904473a32d7b6ab0314b9d",
            "6d3256a2e5fa4bcab3477e7bd252bef6",
            "7b6842f59fd54fc7ad825e16e09217de",
            "b05d4ac4b7c4447392fa2f8a8ffd237e",
            "34ec832256e6475e9a782c517e1a41cb",
            "8e6ad2145f2b40c8b657712de64d8204",
            "f604b312660a4ee4a0d389159697a7ee",
            "bdf724e2889c40a4be8ba351b8881fdd",
            "4082debbab5d4449841b2f1c49121b1a",
            "c2511d48ad7c4f8bb058617e4ac4559c",
            "0010564edd7c4e65944d7a8d80815bcb",
            "21ee485652424423a19d0e323401b850",
            "12564e0a12cd41e2948535c929095ec8",
            "358403596cfd48359a43e0c89bbc8ddd",
            "6cacb9f39bca483c9e1f060c5c966eea",
            "9fb2ee5d75524a4d8b04087c029d238f",
            "e1d6da603af44cc8a79d95383f9cf2b9",
            "93ba8bb8ff5e498a8b06f9ee1031f7dc",
            "9d953a82b09641f4b7f7bcc0161dc9d7",
            "1df34d873e1d44f386f0d1f0c85448be",
            "58c2439431ca40fdaeef36bb575033aa",
            "73d0bad23fe64543a60c66e8f120b478",
            "27c1066b4c2340cbbde9e78ee9e75be9",
            "208d0f1d1bb2455a8e93ad6deeb723be",
            "bc90a8a6eeaa4066b0247bbc23c208ae",
            "88517d762fc242ff9f98eb87ed8e0900",
            "0f63b3999ccf4e94b66b8fbae337c727",
            "a0c9bf4702b545b8891a694331098aac",
            "b14565a0669a475face506503ee84db2",
            "79f5b884e2d8482da29452ae49f750f1",
            "a01f7ab2853d474397421d6149f3dc53"
          ]
        },
        "id": "n5dpzXPW3Fy-",
        "outputId": "c0ccf78e-fa1c-4874-9db1-4fc3d9e951f5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c1633a5dfc44c1d91ab4c6978b3724c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "10001a3a041b43a48b4f6fa91cf8fb34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "784dbe227b494b0d99e28dcc34c28b4a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0aac41b423db4e90bc31c9b3b47d6a09",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a5d801d50f7e4fa3965199a2efa731f3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8d490f44c768453f85f2df139568b9ad",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9eff638e26b34ea6bfd2a1d49be4a447",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "23d714f3ba5048d1bbdd2492e5b99da3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "69ed913670544724990d23967ab8e94e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c2511d48ad7c4f8bb058617e4ac4559c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "58c2439431ca40fdaeef36bb575033aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Embedding model loaded!\n"
          ]
        }
      ],
      "source": [
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "print(\"✅ Embedding model loaded!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4bjc0eLNdIL"
      },
      "source": [
        "Step 5: Encode Texts into Embeddings  \n",
        "I converted all resumes and job descriptions into embeddings using the model.  \n",
        "Now each resume and job description is represented as a high-dimensional vector, enabling similarity calculations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oee5TPBx3KYb",
        "outputId": "1bc1958b-af30-4bfe-be3f-cdde1fa8dee6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Texts converted to embeddings!\n"
          ]
        }
      ],
      "source": [
        "resume_embeddings = model.encode(resumes[\"Resume\"].tolist(), convert_to_tensor=True)\n",
        "job_embeddings = model.encode(jobs[\"Job Description\"].tolist(), convert_to_tensor=True)\n",
        "print(\"✅ Texts converted to embeddings!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F3ABComUNgze"
      },
      "source": [
        "Step 6: Compute Similarity Scores  \n",
        "I calculated the cosine similarity between each resume embedding and each job description embedding.  \n",
        "This produced a similarity matrix where:  \n",
        "- Rows = resumes  \n",
        "- Columns = jobs  \n",
        "- Values = similarity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qccdKuFi3NKe",
        "outputId": "0f3510a4-5549-4f8d-b36e-0f97ff218ca5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Similarity scores computed!\n"
          ]
        }
      ],
      "source": [
        "similarity_matrix = cosine_similarity(resume_embeddings.cpu(), job_embeddings.cpu())\n",
        "print(\"✅ Similarity scores computed!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9l3x6B_Ni8t"
      },
      "source": [
        "Step 7: Rank Resumes for Each Job  \n",
        "For every job description, I ranked all resumes by their similarity score.  \n",
        "I then selected the top 3 resumes that best matched each job."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "slA9BRRb3SMm",
        "outputId": "02b27b2f-bbeb-4634-f9bb-b566be1452c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Ranking completed!\n",
            "   job_id                     job_title  resume_id  match_score  \\\n",
            "0       0  Digital Marketing Specialist        259    26.840000   \n",
            "1       0  Digital Marketing Specialist        264    26.840000   \n",
            "2       0  Digital Marketing Specialist        249    26.840000   \n",
            "3       1                 Web Developer        335    47.250000   \n",
            "4       1                 Web Developer        391    47.250000   \n",
            "5       1                 Web Developer        321    47.250000   \n",
            "6       2            Operations Manager        544    37.040001   \n",
            "7       2            Operations Manager        532    37.040001   \n",
            "8       2            Operations Manager        520    37.040001   \n",
            "9       3              Network Engineer        664    36.889999   \n",
            "\n",
            "                                      resume_excerpt  \n",
            "0  Skill Sets: â¢ Multi-tasking â¢ Collaborativ...  \n",
            "1  Skill Sets: â¢ Multi-tasking â¢ Collaborativ...  \n",
            "2  Skill Sets: â¢ Multi-tasking â¢ Collaborativ...  \n",
            "3  TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C,...  \n",
            "4  TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C,...  \n",
            "5  TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C,...  \n",
            "6  KEY COMPETENCIES â¶Multi - Operations Managem...  \n",
            "7  KEY COMPETENCIES â¶Multi - Operations Managem...  \n",
            "8  KEY COMPETENCIES â¶Multi - Operations Managem...  \n",
            "9  Skill Set â¢ Experience in Implementing, and ...  \n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for job_idx, job in jobs.iterrows():\n",
        "    sims = similarity_matrix[:, job_idx]\n",
        "    top_indices = sims.argsort()[::-1][:3]\n",
        "\n",
        "    for rank, resume_idx in enumerate(top_indices, start=1):\n",
        "        results.append({\n",
        "            \"job_id\": job_idx,\n",
        "            \"job_title\": job[\"Job Title\"],\n",
        "            \"resume_id\": resume_idx,\n",
        "            \"match_score\": round(sims[resume_idx]*100, 2),\n",
        "            \"resume_excerpt\": resumes.iloc[resume_idx][\"Resume\"][:150] + \"...\"\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"✅ Ranking completed!\")\n",
        "print(results_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdRxpEe4Nmdx"
      },
      "source": [
        "Step 8: Display Results  \n",
        "I organized the results into a Pandas DataFrame showing:  \n",
        "- Job ID and title  \n",
        "- Resume ID  \n",
        "- Match score (%)  \n",
        "- Resume excerpt  \n",
        "\n",
        "Finally, I printed the top matches for the first two jobs to demonstrate how the system ranks resumes for different roles."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I694iqX03XIN",
        "outputId": "d2fda68d-7f1b-49dd-adf8-871fe2aff7e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🔹 Job: Digital Marketing Specialist\n",
            " resume_id  match_score                                                                                                                                            resume_excerpt\n",
            "       259        26.84 Skill Sets: â¢ Multi-tasking â¢ Collaborative â¢ Optimistic Thinking â¢ Effective teamleader/team trainer â¢ Visualizing the work which is to be ...\n",
            "       264        26.84 Skill Sets: â¢ Multi-tasking â¢ Collaborative â¢ Optimistic Thinking â¢ Effective teamleader/team trainer â¢ Visualizing the work which is to be ...\n",
            "       249        26.84 Skill Sets: â¢ Multi-tasking â¢ Collaborative â¢ Optimistic Thinking â¢ Effective teamleader/team trainer â¢ Visualizing the work which is to be ...\n",
            "\n",
            "🔹 Job: Web Developer\n",
            " resume_id  match_score                                                                                                                                            resume_excerpt\n",
            "       335        47.25 TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C, C++, BootStrap, JSP, Ext JS Operating Systems: Windows Tools: Toad, Eclipse, SoapBox, Postman Databases...\n",
            "       391        47.25 TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C, C++, BootStrap, JSP, Ext JS Operating Systems: Windows Tools: Toad, Eclipse, SoapBox, Postman Databases...\n",
            "       321        47.25 TECHNICAL SKILLS Skills: Java, SQL, PL/SQL, C, C++, BootStrap, JSP, Ext JS Operating Systems: Windows Tools: Toad, Eclipse, SoapBox, Postman Databases...\n"
          ]
        }
      ],
      "source": [
        "for job_idx in jobs.index[:2]:\n",
        "    print(\"\\n🔹 Job:\", jobs.loc[job_idx, \"Job Title\"])\n",
        "    job_matches = results_df[results_df[\"job_id\"] == job_idx].sort_values(by=\"match_score\", ascending=False)\n",
        "    print(job_matches[[\"resume_id\", \"match_score\", \"resume_excerpt\"]].to_string(index=False))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}